{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd019ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-30 20:04:12,225] [INFO] [307873862.py:58:<module>] Script started...\n",
      "[2025-05-30 20:04:12,226] [INFO] [307873862.py:74:<module>] Using model: google/flan-t5-base\n",
      "[2025-05-30 20:04:12,227] [INFO] [307873862.py:77:<module>] Output location: /home/nub/Bachelor/bachelor-thesis/models/finqa_full_cot\n",
      "[2025-05-30 20:04:12,227] [INFO] [307873862.py:81:<module>] Using 1 CPU core(s)\n",
      "[2025-05-30 20:04:12,227] [INFO] [307873862.py:84:<module>] Using 1 CUDA device(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f6d2b0924147de9ea1f709d8d26b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ['Retrieve the document id: Document: ADI in 2009, interest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) . if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million . foreign currency exposure as more fully described in note 2i . in the notes to consolidated financial statements contained in item 8 of this annual report on form 10-k , we regularly hedge our non-u.s . dollar-based exposures by entering into forward foreign currency exchange contracts . the terms of these contracts are for periods matching the duration of the underlying exposure and generally range from one month to twelve months . currently , our largest foreign currency exposure is the euro , primarily because our european operations have the highest proportion of our local currency denominated expenses . relative to foreign currency exposures existing at october 31 , 2009 and november 1 , 2008 , a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates over the course of the year would not expose us to significant losses in earnings or cash flows because we hedge a high proportion of our year-end exposures against fluctuations in foreign currency exchange rates . the market risk associated with our derivative instruments results from currency exchange rate or interest rate movements that are expected to offset the market risk of the underlying transactions , assets and liabilities being hedged . the counterparties to the agreements relating to our foreign exchange instruments consist of a number of major international financial institutions with high credit ratings . we do not believe that there is significant risk of nonperformance by these counterparties because we continually monitor the credit ratings of such counterparties . while the contract or notional amounts of derivative financial instruments provide one measure of the volume of these transactions , they do not represent the amount of our exposure to credit risk . the amounts potentially subject to credit risk ( arising from the possible inability of counterparties to meet the terms of their contracts ) are generally limited to the amounts , if any , by which the counterparties 2019 obligations under the contracts exceed our obligations to the counterparties . the following table illustrates the effect that a 10% ( 10 % ) unfavorable or favorable movement in foreign currency exchange rates , relative to the u.s . dollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: . fair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability ) . . . . . . . . . $ 20132 $ ( 9457 ) fair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability . . . . . . . . . . . . . . . . . . . . . . $ ( 6781 ) $ ( 38294 ) the calculation assumes that each exchange rate would change in the same direction relative to the u.s . dollar . in addition to the direct effects of changes in exchange rates , such changes typically affect the volume of sales or the foreign currency sales price as competitors 2019 products become more or less attractive . our sensitivity analysis of the effects of changes in foreign currency exchange rates does not factor in a potential change in sales levels or local currency selling prices. .\\nTable:\\n,october 31 2009,november 1 2008\\nfair value of forward exchange contracts asset ( liability ),$ 6427,$ -23158 ( 23158 )\\nfair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability ),$ 20132,$ -9457 ( 9457 )\\nfair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability,$ -6781 ( 6781 ),$ -38294 ( 38294 )\\n'] ['ADI/2009/49']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71db9115c5b431db64ff1444ef921fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False ['Answer the question with a document id: Question: ADI in 2009, what is the the interest expense in 2009?'] ['ADI/2009/49']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e98162c5b44715bc3af9d76669487f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bae8f0fed63402ca21f2091099e4968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-30 20:04:27,764] [INFO] [307873862.py:236:<module>] trainable params: 6,782,976 || all params: 254,360,832 || trainable%: 2.6667\n",
      "[2025-05-30 20:04:27,770] [INFO] [307873862.py:242:<module>] Memory footprint: 455,930,880\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import traceback\n",
    "import multiprocessing\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    EarlyStoppingCallback,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from peft.optimizers import create_loraplus_optimizer\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from config import (\n",
    "    DATA_DOCUMENTS,\n",
    "    DATA_TRAIN_PROC,\n",
    "    DATA_EVAL_PROC,\n",
    "    DATA_TEST_PROC,\n",
    "    MODELS_DIR\n",
    ")\n",
    "\n",
    "DATA_DOCUMENTS = \"/home/nub/Bachelor/bachelor-thesis/data/processed/documents.csv\"\n",
    "DATA_TRAIN_PROC = \"/home/nub/Bachelor/bachelor-thesis/data/processed/train.csv\"\n",
    "DATA_EVAL_PROC = \"/home/nub/Bachelor/bachelor-thesis/data/processed/eval.csv\"\n",
    "DATA_TEST_PROC = \"/home/nub/Bachelor/bachelor-thesis/data/processed/test.csv\"\n",
    "MODELS_DIR = \"/home/nub/Bachelor/bachelor-thesis/models\"\n",
    "\n",
    "# ENVIRONMENT SETUP\n",
    "\n",
    "# Set logging\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s] [%(levelname)s] [%(filename)s:%(lineno)d:%(funcName)s] %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# from transformers.utils import logging as hf_logging\n",
    "# hf_logging.set_verbosity_info()\n",
    "\n",
    "logger.info(\"Script started...\")\n",
    "\n",
    "# Enable debug to drastically reduce values\n",
    "DEBUG = False\n",
    "DEBUG_SIZE = 4\n",
    "SPLITS = [\"train\", \"eval\", \"test\"]\n",
    "\n",
    "COT = False\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = min(4, DEBUG_SIZE) if DEBUG else 16\n",
    "ACCUMULATION_STEPS = 1 if DEBUG else 2\n",
    "LEARNING_RATE = 4e-4\n",
    "EPOCHS = 100\n",
    "\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "logger.info(f\"Using model: {MODEL_NAME}\")\n",
    "\n",
    "OUTPUT_DIR = os.path.join(MODELS_DIR, \"finqa_full_cot\")\n",
    "logger.info(f\"Output location: {OUTPUT_DIR}\")\n",
    "\n",
    "# Detect number of CPUs and GPUs\n",
    "num_cpus = 1 # int(os.getenv(\"SLURM_JOB_CPUS_PER_NODE\", multiprocessing.cpu_count()))\n",
    "logger.info(f\"Using {num_cpus} CPU core(s)\")\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "logger.info(f\"Using {num_gpus} CUDA device(s)\")\n",
    "\n",
    "\n",
    "# DATA PREPROCESSING\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    cache_dir=MODELS_DIR,\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(prompt, target):\n",
    "    model_inputs = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=512,  # Model will silently truncate above 512\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=target,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def build_process_fn(indexing: bool, use_cot: bool):\n",
    "    if indexing:\n",
    "        if use_cot:\n",
    "            prefix = \"Retrieve the document id by reasoning step-by-step: Document: \"\n",
    "        else:\n",
    "            prefix = \"Retrieve the document id: Document: \"\n",
    "\n",
    "        input_key = \"document\"\n",
    "    else:\n",
    "        if use_cot:\n",
    "            prefix = \"Answer the question with a document id by reasoning step-by-step: Question: \"\n",
    "        else:\n",
    "            prefix = \"Answer the question with a document id: Question: \"\n",
    "\n",
    "        input_key = \"question\"\n",
    "\n",
    "    def process_examples(examples):\n",
    "        prompts = []\n",
    "        answers = []\n",
    "        for input_text, docid in zip(examples[input_key], examples[\"document_id\"]):\n",
    "            company, year, page = docid.split(\"/\")\n",
    "\n",
    "            prompt = prefix + f\"{company} in {year}, {input_text}\"\n",
    "            prompts.append(prompt)\n",
    "\n",
    "            if use_cot:\n",
    "                answer = (\n",
    "                    f\"This is about {company} in the year {year} and it is on page {page}. \"\n",
    "                    f\"Therefore, the final answer is {docid}.\"\n",
    "                )\n",
    "            else:\n",
    "                answer = docid\n",
    "            answers.append(answer)\n",
    "\n",
    "        tokenized = tokenize(prompts, answers)\n",
    "        return tokenized\n",
    "    return process_examples\n",
    "\n",
    "\n",
    "# Process documents for indexing\n",
    "raw_documents_ds = load_dataset(\"csv\", data_files=DATA_DOCUMENTS, split=\"train\")\n",
    "documents_ds = raw_documents_ds.map(\n",
    "    build_process_fn(True, COT),\n",
    "    remove_columns=raw_documents_ds.column_names,\n",
    "    num_proc=num_cpus,\n",
    "    batched=True,\n",
    "    batch_size=min(1, len(raw_documents_ds) // num_cpus)\n",
    ")\n",
    "\n",
    "# Process data for retrieval (train, valid, test)\n",
    "file_mapping = {\n",
    "    \"train\": DATA_TRAIN_PROC,\n",
    "    \"eval\": DATA_EVAL_PROC,\n",
    "    \"test\": DATA_TEST_PROC,\n",
    "}\n",
    "\n",
    "# Process queries for retrieval\n",
    "raw_data_ds = load_dataset(\"csv\", data_files=file_mapping)\n",
    "tokenized_ds = raw_data_ds.map(\n",
    "    build_process_fn(False, COT),\n",
    "    remove_columns=raw_data_ds[\"train\"].column_names,\n",
    "    num_proc=num_cpus,\n",
    "    batched=True,\n",
    "    batch_size=min(1, len(raw_data_ds[\"eval\"]) // num_cpus)\n",
    ")\n",
    "\n",
    "# Merge the indexing stage into the train split\n",
    "tokenized_ds[\"train\"] = concatenate_datasets([tokenized_ds[\"train\"], documents_ds])\n",
    "\n",
    "# Reduce data size for all splits\n",
    "if DEBUG:\n",
    "    for split in SPLITS:\n",
    "        tokenized_ds[split] = tokenized_ds[split].select(range(DEBUG_SIZE))\n",
    "        raw_data_ds[split] = raw_data_ds[split].select(range(DEBUG_SIZE))\n",
    "\n",
    "\n",
    "# MODEL SETUP\n",
    "\n",
    "# Quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    cache_dir=MODELS_DIR,\n",
    "    torch_dtype=\"auto\",\n",
    "    local_files_only=True,  # Change for first time downloads\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "# Fix for gradient checkpoints\n",
    "model.config.use_cache = False\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA config (QLoRA + OLoRA)\n",
    "lora_config = LoraConfig(\n",
    "    init_lora_weights=\"olora\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=\"all-linear\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Print model statistics\n",
    "# Code from model.print_trainable_parameters()\n",
    "trainable_params, all_param = model.get_nb_trainable_parameters()\n",
    "\n",
    "logger.info(\n",
    "    f\"trainable params: {trainable_params:,d} || \"\n",
    "    f\"all params: {all_param:,d} || \"\n",
    "    f\"trainable%: {100 * trainable_params / all_param:.4f}\"\n",
    ")\n",
    "\n",
    "logger.info(f\"Memory footprint: {model.get_memory_footprint():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ff481fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"gelu_new\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"gated-gelu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"quantization_config\": {\n",
       "    \"_load_in_4bit\": true,\n",
       "    \"_load_in_8bit\": false,\n",
       "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "    \"bnb_4bit_quant_type\": \"nf4\",\n",
       "    \"bnb_4bit_use_double_quant\": true,\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_has_fp16_weight\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_4bit\": true,\n",
       "    \"load_in_8bit\": false,\n",
       "    \"quant_method\": \"bitsandbytes\"\n",
       "  },\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.52.3\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "560cedac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2789.000000\n",
      "mean      956.324131\n",
      "std       346.305001\n",
      "min       108.000000\n",
      "25%       756.000000\n",
      "50%       935.000000\n",
      "75%      1138.000000\n",
      "max      3477.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "count = []\n",
    "\n",
    "for item in documents_ds[\"input_ids\"]:\n",
    "    count.append(len(item))\n",
    "\n",
    "count_pd = pd.Series(count)\n",
    "print(count_pd.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a272545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9040.000000\n",
      "mean      319.019801\n",
      "std       467.195520\n",
      "min        19.000000\n",
      "25%        31.000000\n",
      "50%        38.000000\n",
      "75%       688.000000\n",
      "max      3477.000000\n",
      "dtype: float64\n",
      "count    883.000000\n",
      "mean      34.375991\n",
      "std        7.738144\n",
      "min       20.000000\n",
      "25%       29.000000\n",
      "50%       32.000000\n",
      "75%       38.000000\n",
      "max       74.000000\n",
      "dtype: float64\n",
      "count    1147.000000\n",
      "mean       34.732345\n",
      "std         7.629443\n",
      "min        21.000000\n",
      "25%        29.000000\n",
      "50%        33.000000\n",
      "75%        39.000000\n",
      "max        75.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "count = {split: [] for split in SPLITS}\n",
    "count_pd = {}\n",
    "\n",
    "for split in SPLITS:\n",
    "    for item in tokenized_ds[split][\"input_ids\"]:\n",
    "        count[split].append(len(item))\n",
    "    \n",
    "    count_pd[split] = pd.Series(count[split])\n",
    "    print(count_pd[split].describe())\n",
    "\n",
    "# mask = count_pd > 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12169443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def contains_whole_word(word, text):\n",
    "    # Strip whitespace from both\n",
    "    word = word.strip()\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Build a regex pattern that matches the exact word as a whole word\n",
    "    pattern = rf'(?i)\\b{re.escape(word)}\\b'  # (?i) for case-insensitive, \\b for word boundaries\n",
    "\n",
    "    # Search using regex\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "decoded_preds = [\"hi/12/34\", \"the answer is Cd/34/56\", \"fe/78/90\"]\n",
    "decoded_labels = [\"ab/12/34\", \"cD/34/56\", \"FE/78/90\"]\n",
    "matches = [\n",
    "        contains_whole_word(label, pred)\n",
    "        for pred, label in zip(decoded_preds, decoded_labels)\n",
    "    ]\n",
    "accuracy = sum(matches) / len(matches)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb84d9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8281.000000\n",
       "mean       11.812342\n",
       "std         0.672473\n",
       "min         9.000000\n",
       "25%        11.000000\n",
       "50%        12.000000\n",
       "75%        12.000000\n",
       "max        14.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = []\n",
    "for i in range(len(tokenized_ds)):\n",
    "    total.append(0 + torch.count_nonzero(tokenized_ds[i][\"labels\"]).numpy())\n",
    "pd.Series(total).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91df2013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADI/2009/page_49.pdf-1\n"
     ]
    }
   ],
   "source": [
    "table = \"year | 2020 | 2021 \\n movies | 12 | 23 \\n games | 67 | 54\"\n",
    "\n",
    "# document = data[\"table\"][0]\n",
    "# input_text = f\"You are a highly intelligent bot. How many games were there in 2020? Here is the table: \\n {table}\"\n",
    "# input_text = f\"You are a highly intelligent bot. The following text is made with HTML. What is second sentence:\\n <h1>I love walking on the beach.</h1><p>My dog is fat.</p><h2>He was yelling at a tree.</h2>\"\n",
    "# input_text = f\"Let's think step by step. Generate the document ID for the document:\\nI think we should go to the beach. Afterwards, we can go the cinema to watch a movie.\"\n",
    "input_text = f\"{train_df['id'][0]}\"\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3eb91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADI/2009/page_49.pdf-1\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length=8192\n",
    ")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    inputs.input_ids.to(model.device),\n",
    "    attention_mask=inputs.attention_mask.to(model.device),\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "output = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92131eb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     50\u001b[39m docid = [\u001b[33m\"\u001b[39m\u001b[33mCOMP/2000/12\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     52\u001b[39m example = {\u001b[33m\"\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m\"\u001b[39m: doc, \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: query, \u001b[33m\"\u001b[39m\u001b[33mdocument_id\u001b[39m\u001b[33m\"\u001b[39m: docid}\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mdoc_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m query_func(example)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mbuild_process_fn.<locals>.process_examples\u001b[39m\u001b[34m(examples)\u001b[39m\n\u001b[32m     19\u001b[39m answers = []\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m examples:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     input_value = \u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     22\u001b[39m     docid = example[\u001b[33m\"\u001b[39m\u001b[33mdocument_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     23\u001b[39m     company, year, page = docid.split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "def build_process_fn(indexing: bool, use_cot: bool):\n",
    "    if indexing:\n",
    "        if use_cot:\n",
    "            prefix = \"Retrieve the document id by reasoning step-by-step: Document: \"\n",
    "        else:\n",
    "            prefix = \"Retrieve the document id: Document: \"\n",
    "\n",
    "        input_key = \"document\"\n",
    "    else:\n",
    "        if use_cot:\n",
    "            prefix = \"Answer the question with a document id by reasoning step-by-step: Question: \"\n",
    "        else:\n",
    "            prefix = \"Answer the question with a document id: Question: \"\n",
    "\n",
    "        input_key = \"question\"\n",
    "\n",
    "    def process_examples(examples):\n",
    "        prompts = []\n",
    "        answers = []\n",
    "        for example in examples:\n",
    "            input_value = example[input_key]\n",
    "            docid = example[\"document_id\"]\n",
    "            company, year, page = docid.split(\"/\")\n",
    "\n",
    "            prompt = prefix + f\"{company} in {year}, {input_value}\"\n",
    "            prompts.append(prompt)\n",
    "\n",
    "            if use_cot:\n",
    "                answer = (\n",
    "                    f\"This is about {company} in the year {year} and it is on page {page}. \"\n",
    "                    f\"Therefore, the final answer is {docid}.\"\n",
    "                )\n",
    "            else:\n",
    "                answer = docid\n",
    "            answers.append(answer)\n",
    "\n",
    "        # tokenized = tokenize(prompts, answers)\n",
    "        print(prompts)\n",
    "        print(answers)\n",
    "        return\n",
    "    return process_examples\n",
    "\n",
    "cot = True\n",
    "\n",
    "doc_func = build_process_fn(True, cot)\n",
    "query_func = build_process_fn(False, cot)\n",
    "\n",
    "doc = [\"DOCUMENT BLA bla DOC\"]\n",
    "query = [\"QUESTION quest?\"]\n",
    "docid = [\"COMP/2000/12\"]\n",
    "\n",
    "example = {\"document\": doc, \"question\": query, \"document_id\": docid}\n",
    "\n",
    "doc_func(example)\n",
    "query_func(example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
