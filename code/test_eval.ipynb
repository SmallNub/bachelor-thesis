{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec13aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nub/Bachelor/bachelor-thesis\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "from utils import (\n",
    "    enable_tf32,\n",
    "    set_seed,\n",
    ")\n",
    "from metrics import compute_metrics\n",
    "from process_data import load_data, DynamicDataset\n",
    "from model import load_tokenizer, load_model\n",
    "from config import SPLITS\n",
    "\n",
    "%cd ..\n",
    "\n",
    "enable_tf32()\n",
    "\n",
    "num_cpus = 16\n",
    "\n",
    "# Enable debug to drastically reduce values\n",
    "DEBUG = False\n",
    "DEBUG_INPUTS = False\n",
    "DEBUG_SIZE = 4\n",
    "\n",
    "USE_COT = False\n",
    "USE_AUG = True\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "N_EXAMPLES = 2\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "SAVE_DIR = \"/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_cot\"\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(SAVE_DIR)\n",
    "model_name = peft_config.base_model_name_or_path\n",
    "\n",
    "tokenizer = load_tokenizer(model_name)\n",
    "model = load_model(model_name, tokenizer, USE_COT)\n",
    "\n",
    "model = PeftModel.from_pretrained(model, SAVE_DIR)\n",
    "\n",
    "_, data = load_data(USE_AUG, DEBUG, DEBUG_SIZE)\n",
    "\n",
    "eval_data = {}\n",
    "for split in SPLITS:\n",
    "    eval_data[split] = DynamicDataset(\n",
    "        data[split],\n",
    "        tokenizer=tokenizer,\n",
    "        documents_ds=None,\n",
    "        format_id=0,\n",
    "        n_examples=N_EXAMPLES,\n",
    "        seed=SEED,\n",
    "        indexing=not USE_AUG,\n",
    "        use_cot=USE_COT,\n",
    "        debug=DEBUG_INPUTS,\n",
    "    )\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3578dfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 3/196 [00:24<26:09,  8.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m SPLITS:\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluating split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m     results[split] = {\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m         **\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     }\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, dataset)\u001b[39m\n\u001b[32m     20\u001b[39m labels = batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m].to(model.device)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     generated_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_max_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m decoded_preds = model.base_model.decode_tokens(generated_ids.detach().cpu().numpy())\n\u001b[32m     33\u001b[39m decoded_labels = model.base_model.decode_tokens(labels.detach().cpu().numpy())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv_thesis/lib/python3.12/site-packages/peft/peft_model.py:2146\u001b[39m, in \u001b[36mPeftModelForSeq2SeqLM.generate\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   2144\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(**kwargs):\n\u001b[32m   2145\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m2146\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv_thesis/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv_thesis/lib/python3.12/site-packages/transformers/generation/utils.py:2616\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n\u001b[32m   2615\u001b[39m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2616\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2617\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2621\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2622\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2623\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2625\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2626\u001b[39m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[32m   2627\u001b[39m     beam_scorer = BeamSearchScorer(\n\u001b[32m   2628\u001b[39m         batch_size=batch_size,\n\u001b[32m   2629\u001b[39m         num_beams=generation_config.num_beams,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2635\u001b[39m         max_length=generation_config.max_length,\n\u001b[32m   2636\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv_thesis/lib/python3.12/site-packages/transformers/generation/utils.py:4021\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   4018\u001b[39m beam_indices = running_beam_indices.detach().clone()\n\u001b[32m   4020\u001b[39m \u001b[38;5;66;03m# 4. run the generation loop\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4021\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_has_unfinished_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis_peer_finished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   4022\u001b[39m     \u001b[38;5;66;03m# a. Forward current tokens, obtain the logits\u001b[39;00m\n\u001b[32m   4023\u001b[39m     flat_running_sequences = \u001b[38;5;28mself\u001b[39m._flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[32m   4024\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/venv_thesis/lib/python3.12/site-packages/transformers/generation/utils.py:2734\u001b[39m, in \u001b[36mGenerationMixin._has_unfinished_sequences\u001b[39m\u001b[34m(self, this_peer_finished, synced_gpus, device)\u001b[39m\n\u001b[32m   2731\u001b[39m         result.past_key_values = result.past_key_values.to_legacy_cache()\n\u001b[32m   2732\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m2734\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_has_unfinished_sequences\u001b[39m(\u001b[38;5;28mself\u001b[39m, this_peer_finished: \u001b[38;5;28mbool\u001b[39m, synced_gpus: \u001b[38;5;28mbool\u001b[39m, device: torch.device) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   2735\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2736\u001b[39m \u001b[33;03m    Returns whether there are still unfinished sequences in the device. The existence of unfinished sequences is\u001b[39;00m\n\u001b[32m   2737\u001b[39m \u001b[33;03m    fed through `this_peer_finished`. ZeRO stage 3-friendly.\u001b[39;00m\n\u001b[32m   2738\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2739\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m synced_gpus:\n\u001b[32m   2740\u001b[39m         \u001b[38;5;66;03m# Under synced_gpus the `forward` call must continue until all gpus complete their sequence.\u001b[39;00m\n\u001b[32m   2741\u001b[39m         \u001b[38;5;66;03m# The following logic allows an early break if all peers finished generating their sequence\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataset):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        collate_fn=data_collator,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=0 if DEBUG else num_cpus,\n",
    "        prefetch_factor=None if DEBUG else 2,\n",
    "        pin_memory=False if DEBUG else True,\n",
    "    )\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(model.device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "        labels = batch[\"labels\"].to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "                max_new_tokens=tokenizer.model_max_length,\n",
    "                num_beams=10,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "        \n",
    "        decoded_preds = model.base_model.decode_tokens(generated_ids.detach().cpu().numpy())\n",
    "        decoded_labels = model.base_model.decode_tokens(labels.detach().cpu().numpy())\n",
    "\n",
    "        all_preds.extend(decoded_preds)\n",
    "        all_labels.extend(decoded_labels)\n",
    "    \n",
    "    metrics, _ = compute_metrics(all_preds, all_labels, USE_COT)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "results = {}\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"Evaluating split: {split}\")\n",
    "    results[split] = {\n",
    "        **evaluate_model(model, eval_data[split])\n",
    "    }\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deda336",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_full_base_pseudo\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.0127699568069108), 'penalty_capped': np.float64(1.0127699568069108), 'penalty_uncapped': np.float64(1.0127699568069108), 'missing': 0.0, 'exact_match_accuracy': 0.9705647096464566, 'part_match_accuracy': 0.9849357436143541, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.2865515288788223), 'penalty_capped': np.float64(1.2865515288788223), 'penalty_uncapped': np.float64(1.2865515288788223), 'missing': 0.0, 'exact_match_accuracy': 0.45300113250283125, 'part_match_accuracy': 0.6543978859947137, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.2886878814298168), 'penalty_capped': np.float64(1.2886878814298168), 'penalty_uncapped': np.float64(1.2886878814298168), 'missing': 0.0, 'exact_match_accuracy': 0.44638186573670446, 'part_match_accuracy': 0.6519907003778002, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642048b6",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_full_base_prompt\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.1170916653335468), 'penalty_capped': np.float64(1.1170916653335468), 'penalty_uncapped': np.float64(1.1170916653335468), 'missing': 0.0, 'exact_match_accuracy': 0.8341065429531275, 'part_match_accuracy': 0.8994827494267531, 'set_match_accuracy': 0.908041380045855, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.3450887127217819), 'penalty_capped': np.float64(1.3450887127217819), 'penalty_uncapped': np.float64(1.3450887127217819), 'missing': 0.0, 'exact_match_accuracy': 0.5209513023782559, 'part_match_accuracy': 0.7095130237825605, 'set_match_accuracy': 0.7258588146470372, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.3277361232199942), 'penalty_capped': np.float64(1.3277361232199942), 'penalty_uncapped': np.float64(1.3277361232199942), 'missing': 0.0, 'exact_match_accuracy': 0.5527462946817786, 'part_match_accuracy': 0.7213019471084022, 'set_match_accuracy': 0.740860215053766, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad6efe",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_full_base_low\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.0816701327787555), 'penalty_capped': np.float64(1.0816701327787555), 'penalty_uncapped': np.float64(1.0857974724044153), 'missing': 0.0, 'exact_match_accuracy': 0.9054551271796513, 'part_match_accuracy': 0.9445155441795946, 'set_match_accuracy': 0.9493840985442297, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.4816459041147605), 'penalty_capped': np.float64(1.4816459041147605), 'penalty_uncapped': np.float64(1.5104643261608155), 'missing': 0.0, 'exact_match_accuracy': 0.4824462061155153, 'part_match_accuracy': 0.6753491883729695, 'set_match_accuracy': 0.6946772366930908, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.4557221737866899), 'penalty_capped': np.float64(1.4557221737866899), 'penalty_uncapped': np.float64(1.4821505376344086), 'missing': 0.0, 'exact_match_accuracy': 0.5047951176983435, 'part_match_accuracy': 0.6887532693984343, 'set_match_accuracy': 0.7145015983725687, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afda61f",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_full_base_5\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.0872346950946008), 'penalty_capped': np.float64(1.0872346950946008), 'penalty_uncapped': np.float64(1.145038127232976), 'missing': 0.0, 'exact_match_accuracy': 0.9046552551591746, 'part_match_accuracy': 0.9430224497413715, 'set_match_accuracy': 0.9473684210526293, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.4494812625132452), 'penalty_capped': np.float64(1.4494812625132452), 'penalty_uncapped': np.float64(1.7561721404303514), 'missing': 0.0, 'exact_match_accuracy': 0.5232163080407701, 'part_match_accuracy': 0.7025292563231402, 'set_match_accuracy': 0.7252170630426575, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.4678271314769105), 'penalty_capped': np.float64(1.4678271314769105), 'penalty_uncapped': np.float64(1.7880557977332177), 'missing': 0.0, 'exact_match_accuracy': 0.5074106364428945, 'part_match_accuracy': 0.6896251089799512, 'set_match_accuracy': 0.7146469049694882, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a7413b",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_full_base_10_fail\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.143484172315532), 'penalty_capped': np.float64(1.143484172315532), 'penalty_uncapped': np.float64(1.2391697328427453), 'missing': 0.0, 'exact_match_accuracy': 0.8435450327947528, 'part_match_accuracy': 0.9059083879912494, 'set_match_accuracy': 0.9136724790700117, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.3992709022117895), 'penalty_capped': np.float64(1.3992709022117895), 'penalty_uncapped': np.float64(1.6751038127595321), 'missing': 0.0, 'exact_match_accuracy': 0.5832389580973952, 'part_match_accuracy': 0.7349943374858449, 'set_match_accuracy': 0.7514911287278228, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.4000266012448492), 'penalty_capped': np.float64(1.4000266012448492), 'penalty_uncapped': np.float64(1.6749055507120025), 'missing': 0.0, 'exact_match_accuracy': 0.5806451612903226, 'part_match_accuracy': 0.7340889276373177, 'set_match_accuracy': 0.7557686718977067, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d08878",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10 - local run\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.1730827122363106), 'penalty_capped': np.float64(1.1730827122363106), 'penalty_uncapped': np.float64(1.290326881032368), 'missing': 0.0, 'exact_match_accuracy': 0.8149096144616861, 'part_match_accuracy': 0.8858049378766015, 'set_match_accuracy': 0.8946355249826652, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.4055336802607197), 'penalty_capped': np.float64(1.4055336802607197), 'penalty_uncapped': np.float64(1.6835787089467724), 'missing': 0.0, 'exact_match_accuracy': 0.5719139297848245, 'part_match_accuracy': 0.731974329935826, 'set_match_accuracy': 0.7477538693846743, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.377799639262459), 'penalty_capped': np.float64(1.377799639262459), 'penalty_uncapped': np.float64(1.6360360360360362), 'missing': 0.0, 'exact_match_accuracy': 0.6006974716652136, 'part_match_accuracy': 0.7502179598953824, 'set_match_accuracy': 0.7669863411798921, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}\n",
    "\n",
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_2 - eval_12656897\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.1727041476025999), 'penalty_capped': np.float64(1.1727041476025999), 'penalty_uncapped': np.float64(1.289710979576601), 'missing': 0.0, 'exact_match_accuracy': 0.8153895376739722, 'part_match_accuracy': 0.8860448994827441, 'set_match_accuracy': 0.8948594891483985, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.4104767536068494), 'penalty_capped': np.float64(1.4104767536068494), 'penalty_uncapped': np.float64(1.691751604379011), 'missing': 0.0, 'exact_match_accuracy': 0.5662514156285391, 'part_match_accuracy': 0.7287655719139311, 'set_match_accuracy': 0.7448093620234059, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.3828317894746809), 'penalty_capped': np.float64(1.3828317894746809), 'penalty_uncapped': np.float64(1.6445945945945948), 'missing': 0.0, 'exact_match_accuracy': 0.5954664341761116, 'part_match_accuracy': 0.7468759081662338, 'set_match_accuracy': 0.7637605347282791, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cad83e",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_cot - eval_12377400\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.1948870535669478), 'penalty_capped': np.float64(1.1948870535669478), 'penalty_uncapped': np.float64(1.3254092678504776), 'missing': 0.00015997440409534473, 'exact_match_accuracy': 0.7885138377859543, 'part_match_accuracy': 0.871913827120989, 'set_match_accuracy': 0.882722764357699, 'structure_score_norm': -0.00015997440409534473, 'structure_score_pos': 0.0, 'structure_score_neg': 0.00015997440409534473},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.3764056100308362), 'penalty_capped': np.float64(1.3764056100308362), 'penalty_uncapped': np.float64(1.6384107210268026), 'missing': 0.0011325028312570782, 'exact_match_accuracy': 0.608154020385051, 'part_match_accuracy': 0.7497168742921869, 'set_match_accuracy': 0.7638354095885249, 'structure_score_norm': -0.0011325028312570782, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0011325028312570782},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.3694422018641628), 'penalty_capped': np.float64(1.3694422018641628), 'penalty_uncapped': np.float64(1.6226242371403663), 'missing': 0.0, 'exact_match_accuracy': 0.6102877070619006, 'part_match_accuracy': 0.7548677709968074, 'set_match_accuracy': 0.7742516710258677, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8aad6",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_ex - eval_12380506\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.118395289878825), 'penalty_capped': np.float64(1.118395289878825), 'penalty_uncapped': np.float64(1.197946995147443), 'missing': 0.0, 'exact_match_accuracy': 0.8725003999360103, 'part_match_accuracy': 0.9220658028048813, 'set_match_accuracy': 0.9285927584919719, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.385036678563092), 'penalty_capped': np.float64(1.385036678563092), 'penalty_uncapped': np.float64(1.650906002265006), 'missing': 0.0, 'exact_match_accuracy': 0.5968289920724802, 'part_match_accuracy': 0.7448093620234066, 'set_match_accuracy': 0.7592676481691215, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.3388400301269252), 'penalty_capped': np.float64(1.3388400301269252), 'penalty_uncapped': np.float64(1.5724498692240627), 'missing': 0.0, 'exact_match_accuracy': 0.6460331299040977, 'part_match_accuracy': 0.7746294681778592, 'set_match_accuracy': 0.7919790758500463, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c559d",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_no_ex - eval_12579165\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.1082237537323392), 'penalty_capped': np.float64(1.1082237537323392), 'penalty_uncapped': np.float64(1.1811976750386606), 'missing': 0.0, 'exact_match_accuracy': 0.8840185570308751, 'part_match_accuracy': 0.928651415773473, 'set_match_accuracy': 0.934623793526367, 'structure_score_norm': -0.00015997440409534473, 'structure_score_pos': 0.0, 'structure_score_neg': 2.6662400682557456e-05},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.3755304144493903), 'penalty_capped': np.float64(1.3755304144493903), 'penalty_uncapped': np.float64(1.6348999622499059), 'missing': 0.0, 'exact_match_accuracy': 0.6070215175537939, 'part_match_accuracy': 0.7512268780671965, 'set_match_accuracy': 0.7645904114760296, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.3582187531308252), 'penalty_capped': np.float64(1.3582187531308252), 'penalty_uncapped': np.float64(1.6057686718977042), 'missing': 0.0, 'exact_match_accuracy': 0.6268526591107236, 'part_match_accuracy': 0.7616971810520236, 'set_match_accuracy': 0.7789886660854435, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2ff23",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_no_cot - eval_12579313\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(1.1110066563142513), 'penalty_capped': np.float64(1.1110066563142513), 'penalty_uncapped': np.float64(1.1855089852290301), 'missing': 0.0, 'exact_match_accuracy': 0.8800191969284914, 'part_match_accuracy': 0.9269983469311539, 'set_match_accuracy': 0.9329867221244574, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(1.4095822559774305), 'penalty_capped': np.float64(1.4095822559774305), 'penalty_uncapped': np.float64(1.6915817289543225), 'missing': 0.0, 'exact_match_accuracy': 0.5707814269535674, 'part_match_accuracy': 0.7280105700264253, 'set_match_accuracy': 0.7477161192902986, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(1.369272273927545), 'penalty_capped': np.float64(1.369272273927545), 'penalty_uncapped': np.float64(1.622682359779134), 'missing': 0.0, 'exact_match_accuracy': 0.6120313862249346, 'part_match_accuracy': 0.7548677709968068, 'set_match_accuracy': 0.7739610578320285, 'structure_score_norm': 0.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1c8ab",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_full - eval_12657074\n",
    "\n",
    "{'train': {'penalty_scaled': np.float64(2.0), 'penalty_capped': np.float64(2.0), 'penalty_uncapped': np.float64(3.675317282568123), 'missing': 0.9492881139017757, 'exact_match_accuracy': 0.0, 'part_match_accuracy': 0.00978510105049858, 'set_match_accuracy': 0.010225030661760778, 'structure_score_norm': -1.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.9830960379672619},\n",
    "\n",
    "'eval': {'penalty_scaled': np.float64(2.0), 'penalty_capped': np.float64(2.0), 'penalty_uncapped': np.float64(3.6755756889392233), 'missing': 0.9490373725934315, 'exact_match_accuracy': 0.0, 'part_match_accuracy': 0.009626274065685165, 'set_match_accuracy': 0.010343525858814649, 'structure_score_norm': -1.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.9826349565873908},\n",
    "\n",
    "'test': {'penalty_scaled': np.float64(2.0), 'penalty_capped': np.float64(2.0), 'penalty_uncapped': np.float64(3.6746294681778546), 'missing': 0.948561464690497, 'exact_match_accuracy': 0.0, 'part_match_accuracy': 0.01002615518744551, 'set_match_accuracy': 0.010520197616971812, 'structure_score_norm': -1.0, 'structure_score_pos': 0.0, 'structure_score_neg': 0.9821272885789013}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe77cea",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_full_ex - eval_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4af4f",
   "metadata": {},
   "source": [
    "/home/nub/Bachelor/bachelor-thesis/models/finqa_base_10_full_cot - eval_\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
